import os
import logging
from aiogram import Bot, Dispatcher, executor, types
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()

BOT_TOKEN = os.getenv("BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

logging.basicConfig(level=logging.INFO)

bot = Bot(token=BOT_TOKEN)
dp = Dispatcher(bot)

client = OpenAI(api_key=OPENAI_API_KEY)

SYSTEM_PROMPT = """
–¢—ã ‚Äî —É–º–Ω—ã–π, –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π AI-–ø–æ–º–æ—â–Ω–∏–∫ –≤ Telegram.
–¢—ã —É–º–µ–µ—à—å:
- –≤–µ—Å—Ç–∏ –æ–±—ã—á–Ω—ã–π –¥–∏–∞–ª–æ–≥
- –ø–∏—Å–∞—Ç—å —ç—Å—Å–µ
- —Å–æ—á–∏–Ω—è—Ç—å –ø–µ—Å–Ω–∏
- –ø–∏—Å–∞—Ç—å —Å—Ç–∏—Ö–∏
- –ø–æ–º–æ–≥–∞—Ç—å —Å –∏–¥–µ—è–º–∏ –∏ –º—ã—Å–ª—è–º–∏

–û—Ç–≤–µ—á–∞–π —è—Å–Ω–æ, –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ –∏ –ø–æ —Ç–µ–º–µ.
–§–æ—Ä–º–∞—Ç –≤—ã–±–∏—Ä–∞–π —Å–∞–º, –∏—Å—Ö–æ–¥—è –∏–∑ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
"""

@dp.message_handler(commands=["start"])
async def start(message: types.Message):
    await message.answer(
        "–ü—Ä–∏–≤–µ—Ç üëã\n\n"
        "–Ø –º–æ–≥—É –æ–±—â–∞—Ç—å—Å—è —Å —Ç–æ–±–æ–π, –ø–∏—Å–∞—Ç—å —ç—Å—Å–µ, —Å—Ç–∏—Ö–∏, –ø–µ—Å–Ω–∏ –∏ –ª—é–±—ã–µ —Ç–µ–∫—Å—Ç—ã.\n"
        "–ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏, —á—Ç–æ —Ç–µ–±–µ –Ω—É–∂–Ω–æ üôÇ"
    )

@dp.message_handler()
async def chat_with_gpt(message: types.Message):
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": message.text}
            ],
            temperature=0.9,
            max_tokens=800
        )

        answer = response.choices[0].message.content
        await message.answer(answer)

    except Exception as e:
        logging.exception(e)
        await message.answer("‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞. –ü–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ.")

if __name__ == "__main__":
    executor.start_polling(dp, skip_updates=True)
